{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "import tqdm\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Model, Input, regularizers\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_buildings = \"./seg_train/seg_train/buildings\"\n",
    "# path_forest = \"./seg_train/seg_train/forest\"\n",
    "# path_glacier = \"./seg_train/seg_train/glacier\"\n",
    "# path_mountain = \"./seg_train/seg_train/mountain\"\n",
    "# path_sea = \"./seg_train/seg_train/sea\"\n",
    "# path_street = \"./seg_train/seg_train/street\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays of image vectors (150 X 150 X 3)\n",
    "all_images = []\n",
    "\n",
    "for file in os.listdir(path_buildings):\n",
    "      img = image.load_img(path_buildings + \"/\"+file, target_size=(80,80,3))\n",
    "      img = image.img_to_array(img)\n",
    "      img = img/255.\n",
    "      all_images.append(img)\n",
    "\n",
    "\n",
    "# buildings = [imread(path_buildings + \"/\" + file) for file in os.listdir(path_buildings)]\n",
    "#buildings = np.asarray(buildings)\n",
    "# forest = [imread(path_forest + \"/\" + file) for file in os.listdir(path_forest)]\n",
    "# #forest = np.asarray(forest)\n",
    "# glacier = [imread(path_glacier + \"/\" + file) for file in os.listdir(path_glacier)]\n",
    "# #glacier = np.asarray(glacier)\n",
    "# mountain = [imread(path_mountain + \"/\" + file) for file in os.listdir(path_mountain)]\n",
    "# #mountain = np.asarray(mountain)\n",
    "# sea = [imread(path_sea + \"/\" + file) for file in os.listdir(path_sea)]\n",
    "# #sea = np.asarray(buildings)\n",
    "# street = [imread(path_street + \"/\" + file) for file in os.listdir(path_street)]\n",
    "#street = np.asarray(street)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = train_test_split(all_images, random_state=32, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hp/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model Building of an image\n",
    "\n",
    "\n",
    "Input_img = keras.Input(shape=(80, 80, 3)) \n",
    "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
    "x2 = MaxPool2D( (2, 2))(x2)\n",
    "encoded = Conv2D(64, (3, 3), activation='softmax', padding='same')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding Architecture\n",
    "\n",
    "x3 = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x3 = UpSampling2D((2, 2))(x3)\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x3)\n",
    "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(x2)\n",
    "decoded = Conv2D(3, (3, 3), padding='same')(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80, 80, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 80, 80, 256)       7168      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 80, 80, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 40, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 80, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 80, 80, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 80, 80, 3)         6915      \n",
      "=================================================================\n",
      "Total params: 788,867\n",
      "Trainable params: 788,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hp/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1971 samples, validate on 220 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, mode='auto')\n",
    "a_e = autoencoder.fit(train_x, train_x,\n",
    "            epochs=10,\n",
    "            batch_size=256,\n",
    "            shuffle=True,\n",
    "            validation_data=(val_x, val_x),\n",
    "            callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
